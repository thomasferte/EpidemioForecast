---
title: "Experience 1 - reporting"
format: gfm
editor: source
echo: false
message: false
warning: false
prefer-html: true
---

```{r}
set.seed(1)
library(tidyverse)
source(here::here("script/fct_compute_performance.R"))
```

```{r}
path_experience1 <- here::here("output/experience1/aggregated_results/")
color_methods <- c("#94C9A9", "#FB8B24", "#454372", "black", "darkgrey")
```

# PREDICTION

```{r}
##### IMPORT FILES
ls_prediction_performance <- fct_compute_prediction(path_files = path_experience1)

df_performance <- fct_compute_performance(df_prediction_by_day = ls_prediction_performance$df_prediction_by_day)
```

### Sanity check

First, we check that there is 40 reservoir prediction for each day of
the prediction for each scenario. We observe that there is indeed a
forecast for each day. Some days have less than 40 reservoirs but the
minimum is 39 which seems acceptable.

```{r sanitycheckNbReservoirPerDay}
#| fig-cap: "Number of reservoir per day for prediction"
#| fig-height: 6
#| 
ls_prediction_performance$df_prediction %>%
  group_by(hp_date, model, outcomeDate, features, starting_date, update) |> 
  summarise(n = n(), .groups = "drop") %>%
  full_join(expand.grid(update = unique(ls_prediction_performance$df_prediction$update),
                        model = unique(ls_prediction_performance$df_prediction$model),
                        outcomeDate = unique(ls_prediction_performance$df_prediction$outcomeDate),
                        features = unique(ls_prediction_performance$df_prediction$features),
                        starting_date = unique(ls_prediction_performance$df_prediction$starting_date)),
            by = c("update",
                   "model",
                   "outcomeDate",
                   "features",
                   "starting_date")) %>%
  mutate(model_string = paste(model,
                              features,
                              sep = "_")) %>%
  ggplot(mapping = aes(x = outcomeDate,
                       y = n,
                       color = update)) +
  geom_line() +
  facet_grid(model_string ~ starting_date, scales = "free_y") +
  theme_bw() +
  theme(strip.text.y = element_text(angle = 0)) +
  labs(x = "Date", y = "Nb of models")
```

### Prediction

```{r PredictionByDayByModel}
#| fig-cap: "Prediction by day by model"
#| fig-height: 8
#| 
ls_prediction_performance$df_prediction_by_day %>%
  mutate(pred = if_else(pred > 200, 200, pred)) %>%
  ggplot(mapping = aes(x = outcomeDate, y = pred, color = model, linetype = features)) +
  geom_line() +
  geom_line(mapping = aes(y = outcome, color = "Observed"), na.rm = TRUE) +
  geom_line(mapping = aes(y = hosp, color = "Baseline")) +
  scale_color_manual(values = color_methods) +
  scale_y_continuous(limits = c(0, 200)) +
  scale_x_date(breaks = "2 months") +
  facet_grid(update ~ starting_date) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90)) +
  labs(x = "Date",
       y = "Hospitalizations",
       color = "Model",
       linetype = "Features")
```


### Performance

#### Forecast Error by month

```{r}
ls_prediction_performance$df_performance_by_month %>%
  ggplot(mapping = aes(x = outcomeMonth, y = MAE, color = model, shape = features)) +
  geom_point() +
  scale_color_manual(values = color_methods) +
  scale_y_log10() +
  facet_grid(update ~ starting_date) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90)) +
  labs(x = "Month",
       y = "Mean Absolute Error",
       color = "Model",
       shape = "Features")
```

```{r}
ls_prediction_performance$df_performance_by_month %>%
  mutate(MAEB = if_else(MAEB > 10, 10, MAEB)) %>%
  ggplot(mapping = aes(x = outcomeMonth, y = MAEB, color = model, shape = features)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  scale_color_manual(values = color_methods) +
  facet_grid(update ~ starting_date) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90)) +
  labs(x = "Month",
       y = "Mean Absolute Error compared to Baseline",
       color = "Model",
       shape = "Features")
```

#### Overall performance

```{r}
#| tbl-cap: "Performance by algorithm initiated in 2020-08-15 from 2020-08-29 to 2021-03-15"
ls_prediction_performance$df_prediction_by_day %>%
  filter(outcomeDate < "2021-03-15") %>%
  fct_compute_performance() %>%
  dplyr::select(model, features, update, MAE, MRE, MAEB, MREB, starting_date) %>%
  gt::gt(
    rowname_col = "features",
    groupname_col = "model",
    row_group_as_column = TRUE
  )
```

```{r}
#| tbl-cap: "Performance by algorithm initiated in 2021-03-01 from 2021-03-15 to 2022-01-17."
ls_prediction_performance$df_prediction_by_day %>%
  filter(starting_date == "2021-03-01") %>%
  fct_compute_performance() %>%
  dplyr::select(model, features, update, MAE, MRE, MAEB, MREB, starting_date) %>%
  gt::gt(
    rowname_col = "features",
    groupname_col = "model",
    row_group_as_column = TRUE
  )
```

```{r overallPerf}
#| fig-cap: "Overall performance of the different methods"
#| fig-height: 6
#| 
graph_perf <- ls_prediction_performance$df_prediction_by_day %>%
  fct_compute_performance() %>%
  ggplot(mapping = aes(x = features, y = AE, color = model)) +
  geom_point(position = position_dodge(width = .5)) +
  scale_color_manual(values = color_methods) +
  theme_bw() +
  facet_grid(starting_date ~ update, scales = "free_y") +
  labs(y = "Mean absolute error",
       x = "Features",
       color = "Update")

graph_perf
```

# Hyperparameters

```{r}
vec_numeric_hp <- c("n_estimators",
                    "max_depth",
                    "learning_rate",
                    "subsample",
                    "colsample_bytree",
                    "spectral_radius",
                    "leaking_rate",
                    "input_scaling",
                    "ridge",
                    "l1_ratio")

files_hyperparameters <- list.files(path = path_experience1,
                                    full.names = TRUE,
                                    pattern = "_hyperparameters")
names(files_hyperparameters) <- list.files(path = path_experience1,
                                           pattern = "_hyperparameters")

df_hyperparameters <- lapply(names(files_hyperparameters),
                             function(name_file_i) readr::read_csv(files_hyperparameters[name_file_i]) %>%
                               mutate(across(.cols = any_of(vec_numeric_hp),
                                             .fns = as.numeric)) %>%
                               mutate(model = name_file_i,
                                      .before = 1)) |>
  bind_rows() %>%
  tibble::rowid_to_column(var = "genetic_id") |>
  separate(model,
           sep = "_",
           into = c("trash_method",
                    "model",
                    "trash_date",
                    "starting_date",
                    "trash_features",
                    "features",
                    "trash_prediction")) %>%
  select(-starts_with("trash_")) %>%
  mutate(last_used_observation = stringr::str_extract(string = file_hp,
                                                      pattern = "\\d{4}-\\d{2}-\\d{2}"),
         last_used_observation = as.Date(last_used_observation))

## get the best 40 by date
df_all_hp_best40 <- df_hyperparameters %>%
  group_by(model, starting_date, features, last_used_observation) %>%
  slice_min(value, n = 40) |>
  ungroup() %>%
  select(genetic_id, model, starting_date, features, last_used_observation, all_of(vec_numeric_hp)) |>
  tidyr::pivot_longer(cols = all_of(vec_numeric_hp), names_to = "hyperparameter") |>
  mutate(last_used_observation = as.factor(last_used_observation),
         last_used_observation = forcats::fct_rev(last_used_observation))

df_all_hp_best1 <- df_hyperparameters %>%
  group_by(model, starting_date, features, last_used_observation) %>%
  slice_min(value, n = 1) |>
  ungroup() %>%
  select(genetic_id, model, starting_date, features, last_used_observation, all_of(vec_numeric_hp)) |>
  tidyr::pivot_longer(cols = all_of(vec_numeric_hp), names_to = "hyperparameter") |>
  mutate(last_used_observation = as.factor(last_used_observation),
         last_used_observation = forcats::fct_rev(last_used_observation))


```


## Sanity check

```{r}
df_hyperparameters |>
  filter(value != 1000) %>%
  group_by(last_used_observation, model, starting_date, features) |>
  summarise(n = n(), .groups = "drop") |>
  ggplot(mapping = aes(x = last_used_observation, y = n, fill = model)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_grid(starting_date ~ features) +
  scale_fill_manual(values = color_methods) +
  labs(y = "nb of genetic individuals",
       x = "update date") +
  theme_minimal()
```

## Numeric hyperparameters

### Hyperparameter evolution

```{r}
#| fig-cap: "Numeric hyperparameter, density of 40 best individuals per hyperparameter update date."
#| fig-height: 16
#| 
plot_best_numeric_hp_reservoir <- df_all_hp_best40 |>
  filter(model == "reservoir") %>%
  ggplot(mapping = aes(x = value,
                       y = last_used_observation,
                       group = interaction(last_used_observation, hyperparameter),
                       fill = hyperparameter,
                       color = hyperparameter)) +
  ggridges::geom_density_ridges(alpha = 0.5) +
  facet_grid(starting_date ~ features, scales = "free_y", switch = "both") +
  scale_x_log10(breaks = c(1e-10, 1e-5, 1, 1e5)) +
  theme_bw() +
  theme(legend.position = "bottom") +
  labs(x = "Hyperparameter value",
       y = "Update Date")

plot_best_numeric_hp_xgboost <- df_all_hp_best40 |>
  filter(model == "xgboost") %>%
  ggplot(mapping = aes(x = value,
                       y = last_used_observation,
                       group = interaction(last_used_observation, hyperparameter),
                       fill = hyperparameter,
                       color = hyperparameter)) +
  ggridges::geom_density_ridges(alpha = 0.5) +
  facet_grid(starting_date ~ features, scales = "free_y", switch = "both") +
  scale_x_log10(breaks = c(1e-10, 1e-5, 1, 1e5)) +
  theme_bw() +
  theme(legend.position = "bottom") +
  labs(x = "Hyperparameter value",
       y = "Update Date")

plot_best_numeric_hp_enet <- df_all_hp_best40 |>
  filter(model == "enet") %>%
  ggplot(mapping = aes(x = value,
                       y = last_used_observation,
                       group = interaction(last_used_observation, hyperparameter),
                       fill = hyperparameter,
                       color = hyperparameter)) +
  ggridges::geom_density_ridges(alpha = 0.5) +
  facet_grid(starting_date ~ features, scales = "free_y", switch = "both") +
  scale_x_log10(breaks = c(1e-10, 1e-5, 1, 1e5)) +
  theme_bw() +
  theme(legend.position = "bottom") +
  labs(x = "Hyperparameter value",
       y = "Update Date")

ggpubr::ggarrange(plot_best_numeric_hp_reservoir,
                  plot_best_numeric_hp_enet,
                  plot_best_numeric_hp_xgboost,
                  nrow = 3,
                  ncol = 1)

```

# Time and carbon footprint

```{r}
file_emissions = paste0(path_experience1, "emissions_logs.csv")
vec_time_labeller <- c("CO2eq (kg)",
                       "Energy (kWh)",
                       "Time (h)")
names(vec_time_labeller) <- c("total_max_emissions",
                              "total_max_energy",
                              "total_max_time")

df_emissions <- readr::read_csv(file_emissions) %>%
  separate(project_name,
           sep = "_",
           into = c("trash_method",
                    "model",
                    "trash_date",
                    "starting_date",
                    "trash_features",
                    "features",
                    "trash_prediction")) %>%
  select(-starts_with("trash_")) %>%
  mutate(train_test = factor(grepl(x = file_hp,
                                   pattern = "evaluate_id_test_"),
                             levels = c(TRUE, FALSE),
                             labels = c("Test", "Train"))) %>%
  group_by(model, starting_date, features, train_test) %>%
  summarise(mean_emissions = mean(emissions),
            mean_energy = mean(energy_consumed),
            mean_time = mean(duration)/3600,
            nb_jobs = n(),
            .groups = "drop") %>%
  mutate(theoric_nb_jobs = case_when(train_test == "Test" & starting_date == "2020-08-15" ~ 18,
                                     train_test == "Test" & starting_date == "2021-03-01" ~ 11,
                                     train_test == "Train" ~ 200),
         total_max_emissions = mean_emissions * theoric_nb_jobs,
         total_max_energy = mean_energy * theoric_nb_jobs,
         total_max_time = mean_time * theoric_nb_jobs)
```

```{r}
df_emissions %>%
  filter(starting_date == "2020-08-15") %>%
  select(model, starting_date, features, train_test, starts_with("total")) %>%
  tidyr::pivot_longer(cols = starts_with("total")) %>%
  ggplot(mapping = aes(x = features, y = value, color = model, shape = train_test)) +
  geom_point(position = position_dodge(width = .5)) +
  scale_color_manual(values = color_methods) +
  scale_shape_manual(values = c(0, 16)) +
  facet_wrap(name ~ train_test,
             scales = "free_y",
             labeller = labeller(name = vec_time_labeller),
             ncol = 2) +
  theme_bw() +
  labs(shape = "Train or test set",
       color = "Model",
       x = "Features")

```

```{r}
df_performance_vs_CO2_tempCO2 <- df_emissions %>%
  group_by(model, starting_date, features) %>%
  summarise(total_max_emissions = sum(total_max_emissions),
            .groups = "drop")

df_performance_vs_CO2 <- ls_prediction_performance$df_prediction_by_day %>%
  fct_compute_performance() %>%
  filter(update == "Monthly update",
         starting_date == "2020-08-15") %>%
  select(model, starting_date, features, AE) %>%
  left_join(df_performance_vs_CO2_tempCO2,
            by = c("model", "starting_date", "features"))

df_performance_vs_CO2 %>%
  ggplot(mapping = aes(x = total_max_emissions, y = AE, color = model, shape = features)) +
  geom_point(size = 3) +
  scale_color_manual(values = color_methods) +
  scale_shape_manual(values = c(8, 18)) +
  theme_bw() +
  labs(x = "train + test CO2eq (kg)",
       y = "Mean Absolute Error",
       color = "Model",
       shape = "Features")
```

