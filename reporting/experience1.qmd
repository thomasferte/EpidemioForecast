---
title: "Experience 1 - reporting"
format: gfm
toc: true
number-sections: true
editor: source
echo: false
message: false
warning: false
prefer-html: true
---

```{r}
set.seed(1)
library(tidyverse)
source(here::here("script/fct_compute_performance.R"))
```

```{r}
vec_path_experience <- c(here::here("output/experience1/aggregated_results/"),
                         here::here("output/experience2/aggregated_results/"),
                         here::here("output/experience3/aggregated_results/"))

color_methods <- viridis::inferno(n = 3, end = 0.9)
```

# Introduction

Goal = provide some results to write the article of the SARS-CoV-2 forecast from an implementation science perspective.

Hypothesis to test :

- Simple models like elastic-net perform better when little information is available
- Feature selection based on epidemic knowledge performs better when little information is available
- More complex models like xgboost or reservoir computing show an advantage only on the late phase of the epidemic
- Simple models are faster and have lighter carbon footprint

# Methods

Same setting as ICML paper.

We compare different scenario :

- 3 methods : elastic-net, xgboost, reservoir computing
- 2 features selection : all features provided (GA feature selection for reservoir computing), epidemiology informed features selection (no GA feature selection for reservoir computing).
- monthly update and no monthly update
- two period : one starts on 2020-09-02, the other one starts on 2021-03-01

In order to evaluate the robustness of the results regarding the variability of reservoir and hyperparameter optimization we repeat the experiment three times. 

Expected results:

- Elastic-net > xgboost on early period
- Reservoir computing > Elastic-net on all period (add memory and non linearity)
- XGboost ~= Reservoir computing on late period (complex models are better in late period)
- Epidemio feature selection > Data driven feature selection on early period (add expert knowledge has strong importance in the early period)
- Elastic-net carbon footprint and time <<<<< XGboost and Reservoir computing

# Prediction

```{r}
##### IMPORT FILES
ls_prediction_performance_all <- lapply(X = vec_path_experience, FUN = fct_compute_prediction)

df_prediction <- lapply(1:length(ls_prediction_performance_all),
                        function(i) ls_prediction_performance_all[[i]]$df_prediction %>%
                          mutate(rep = i, .before = 0)
                        ) %>%
  bind_rows()

```

### Sanity check

First, we check that there is 40 reservoir prediction for each day of
the prediction for each scenario. At figure @fig-sanitycheckNbReservoirPerDay, we observe that there is indeed a
forecast for each day. Some days have less than 40 reservoirs but the
minimum is 39 which seems acceptable.

```{r sanitycheckNbReservoirPerDay}
#| fig-cap: "Number of reservoir per day for prediction"
#| label: fig-sanitycheckNbReservoirPerDay
#| fig-height: 4
#| 
df_prediction %>%
  group_by(hp_date, model, outcomeDate, features, starting_date, update, rep) |> 
  summarise(n = n(), .groups = "drop") %>%
  full_join(expand.grid(rep = unique(df_prediction$rep),
                        update = unique(df_prediction$update),
                        model = unique(df_prediction$model),
                        outcomeDate = unique(df_prediction$outcomeDate),
                        features = unique(df_prediction$features),
                        starting_date = unique(df_prediction$starting_date)),
            by = c("rep",
                   "update",
                   "model",
                   "outcomeDate",
                   "features",
                   "starting_date")) %>%
  filter(!(rep %in% c(2,3) & starting_date != "2021-03-01")) %>%
  filter(outcomeDate >= as.Date(starting_date)+14) %>%
  mutate(model_string = paste(model,
                              features,
                              sep = "_"),
         n = if_else(is.na(n), 0, n)) %>%
  ggplot(mapping = aes(x = outcomeDate,
                       y = n,
                       color = as.factor(rep),
                       shape = update)) +
  geom_line() +
  scale_y_continuous(labels = round,
                     breaks = round) +
  facet_grid(model_string ~ starting_date, scales = "free_y") +
  theme_bw() +
  theme(strip.text.y = element_text(angle = 0)) +
  labs(x = "Date", y = "Number of models", color = "Repetition id")
```

### Prediction

First we show a graphical evaluation of the different algorithms. On panel A of figure @fig-PredictionByDayByModel we first observe that xgboost led to highly volatile predictions when little information is available, persisting when using all features without updating hyperparameters. At the contrary, both elastic-net and reservoir computing where quite robust regarding hyperparameter choice. When more information is available such as presented at panel B, all models where quite stable and updating the hyperparameters had little effect.

Regarding the graphical performance at the early phase of the epidemic, xgboost seemed worse compared to elastic-net and reservoir computing due to this high volatility. However, when more information is available 

```{r PredictionByDayByModel}
#| fig-cap: "Prediction by day by model. Only results of the first repetition are shown."
#| label: fig-PredictionByDayByModel
#| fig-height: 10
plot_early <- make_plot_daily_prediction(string_date = "2020-09-02",
                                         data = ls_prediction_performance_all[[1]]$df_prediction_by_day) +
  ggtitle('A. Models start at 2020-09-02')
plot_late <- make_plot_daily_prediction(string_date = "2021-03-01",
                                        data = ls_prediction_performance_all[[1]]$df_prediction_by_day) +
  ggtitle('B. Models start at 2021-03-01')

ggpubr::ggarrange(plot_early, plot_late, common.legend = TRUE, legend = "right", ncol = 1, nrow = 2)
```

### Performance

#### Forecast Error by month

```{r}
#| fig-cap: "Forecast performance by month depending on model, update frequency and features used. Erros greater than 50 are set to 50 for visualisation."
#| fig-height: 4
#| 
ls_prediction_performance_all[[1]]$df_performance_by_month %>%
  mutate(MAE = if_else(MAE > 50, 50, MAE)) %>%
  ggplot(mapping = aes(x = outcomeMonth, y = MAE, color = model, shape = features)) +
  geom_point() +
  scale_color_manual(values = color_methods) +
  facet_grid(update ~ starting_date) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90)) +
  labs(x = "Month",
       y = "Mean Absolute Error",
       color = "Model",
       shape = "Features")
```

```{r}
#| fig-cap: "Mean Absoluter Error compared to baseline by month depending on model, update frequency and features used. Models below horitzontal line underperform compared to baseline model and therefore are useless. Erros greater than 10 are set to 10 for visualisation."
#| fig-height: 4
#| 
ls_prediction_performance_all[[1]]$df_performance_by_month %>%
  mutate(MAEB = if_else(MAEB > 10, 10, MAEB)) %>%
  ggplot(mapping = aes(x = outcomeMonth, y = MAEB, color = model, shape = features)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  scale_color_manual(values = color_methods) +
  facet_grid(update ~ starting_date) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90)) +
  labs(x = "Month",
       y = "Mean Absolute Error compared to Baseline",
       color = "Model",
       shape = "Features")
```

#### Overall performance

```{r}
#| tbl-cap: "Performance by algorithm initiated in 2020-09-02 from 2020-09-02 to 2021-03-15"
ls_prediction_performance_all[[1]]$df_prediction_by_day %>%
  filter(outcomeDate < "2021-03-15") %>%
  fct_compute_performance() %>%
  dplyr::select(model, features, update, MAE, MRE, MAEB, MREB, starting_date) %>%
  labelled::set_variable_labels(MAE = "MAE (+/- SD)",
                                MRE = "MRE (+/- SD)",
                                MAEB = "MAEB (+/- SD)",
                                MREB = "MREB (+/- SD)") %>%
  gt::gt(
    rowname_col = "features",
    groupname_col = "model",
    row_group_as_column = TRUE
  )
```

```{r}
#| tbl-cap: "Performance by algorithm initiated in 2021-03-01 from 2021-03-15 to 2022-01-17."
df_perf_all_rep <- lapply(1:length(ls_prediction_performance_all),
       function(i){
         ls_prediction_performance_all[[i]]$df_prediction_by_day %>%
           mutate(rep = i, .before = 0)
         }) %>%
  bind_rows() %>%
  filter(starting_date == "2021-03-01") %>%
  group_by(rep, model, starting_date, features, update) %>%
  summarise(MAE = mean(AE, na.rm = T),
            MRE = median(RE, na.rm = T),
            MAEB = mean(AE_baseline, na.rm = T),
            MREB = median(RE_baseline, na.rm = T),
            .groups = "drop") 

df_perf_all_rep %>%
  group_by(model, starting_date, features, update) %>%
  summarise(across(c("MAE", "MRE", "MAEB", "MREB"),
                   function(i) paste0(round(median(i), 2), " (",
                                      round(min(i), 2), " ; ",
                                      round(max(i), 2), ")")),
            .groups = "drop") %>%
  gt::gt(
    rowname_col = "features",
    groupname_col = "model",
    row_group_as_column = TRUE
  )
```

```{r overallPerf}
#| fig-cap: "Performance by algorithm initiated in 2021-03-01 from 2021-03-15 to 2022-01-17. Erros greater than 25 are set to 25 for visualisation."
#| fig-height: 3
#| 

df_perf_all_rep %>%
  group_by(model, starting_date, features, update) %>%
  summarise(median_MAE = median(MAE),
            min_MAE = min(MAE),
            max_MAE = max(MAE),
            .groups = "drop") %>%
  ggplot(mapping = aes(x = features, y = median_MAE, ymin = min_MAE, ymax = max_MAE, color = model)) +
  geom_errorbar(position = position_dodge(width = .5), width = 0.3) +
  geom_point(position = position_dodge(width = .5)) +
  scale_color_manual(values = color_methods) +
  theme_bw() +
  facet_grid(. ~ update, scales = "free_y") +
  labs(y = "Mean absolute error",
       x = "Features",
       color = "Model")
```

# Hyperparameters

```{r}
ls_hyperparameters <- fct_compute_hyperparameters(path = vec_path_experience[[1]])
```


## Sanity check

```{r}
#| fig-cap: "Numbers of trial per model and date. Sanity check."
#| fig-height: 6
#| 
ls_hyperparameters$df_hyperparameters |>
  filter(value != 1000) %>%
  group_by(last_used_observation, model, starting_date, features) |>
  summarise(n = n(), .groups = "drop") |>
  ggplot(mapping = aes(x = last_used_observation, y = n, fill = model)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_grid(starting_date ~ features) +
  scale_fill_manual(values = color_methods) +
  labs(y = "nb of genetic individuals",
       x = "update date") +
  theme_bw()
```

```{r}
#| fig-cap: "Q1-Q3 distribution of numeric hyperparameters. Sanity check."
#| fig-height: 12
#| 
ls_hyperparameters$df_all_hp %>%
  group_by(model, starting_date, features, last_used_observation, hyperparameter) %>%
  summarise(q1 = quantile(value, 0.25),
            q3 = quantile(value, 0.75)) %>%
  ggplot(mapping = aes(xmin = q1, xmax = q3, y = last_used_observation,
                       color = interaction(features, starting_date))) +
  geom_errorbarh() +
  scale_color_viridis_d(option = "A", end = 0.9) +
  facet_wrap(model ~ hyperparameter, scales = "free_x", ncol = 3) +
  theme_bw() +
  theme(legend.position = "bottom") +
  labs(color = "Features x Starting date") +
  guides(color=guide_legend(nrow=2,byrow=TRUE))

```

## Numeric hyperparameters

### Hyperparameter evolution

```{r}
#| fig-cap: "Numeric hyperparameter, density of 40 best individuals per hyperparameter update date."
#| fig-height: 10
#| 

plot_best_numeric_hp_reservoir <- ls_hyperparameters$df_all_hp_best40 |>
  filter(model == "reservoir") %>%
  ggplot(mapping = aes(x = value,
                       y = features,
                       color = last_used_observation)) +
  geom_point(position = position_dodge2(width = .4, reverse = TRUE), shape = 1, alpha = .5) +
  geom_point(data = ls_hyperparameters$df_all_hp_best1 %>% filter(model == "reservoir"),
             position = position_dodge2(width = .4, reverse = TRUE),
             mapping = aes(color = "Best")) +
  scale_color_manual(values = c(viridis::viridis(n = 17), "red")) +
  facet_grid(starting_date ~ hyperparameter, scales = "free_x", switch = "both") +
  theme_bw() +
  labs(x = "Hyperparameter value",
       y = "Update Date",
       color = "HP update")

plot_best_numeric_hp_xgboost <- ls_hyperparameters$df_all_hp_best40 |>
  filter(model == "xgboost") %>%
  ggplot(mapping = aes(x = value,
                       y = features,
                       color = last_used_observation)) +
  geom_point(position = position_dodge2(width = .4, reverse = TRUE), shape = 1, alpha = .5) +
  geom_point(data = ls_hyperparameters$df_all_hp_best1 %>% filter(model == "xgboost"),
             position = position_dodge2(width = .4, reverse = TRUE),
             mapping = aes(color = "Best")) +
  scale_color_manual(values = c(viridis::viridis(n = 17), "red")) +
  facet_grid(starting_date ~ hyperparameter, scales = "free_x", switch = "both") +
  theme_bw() +
  labs(x = "Hyperparameter value",
       y = "Update Date",
       color = "HP update")

plot_best_numeric_hp_enet <- ls_hyperparameters$df_all_hp_best40 |>
  filter(model == "enet") %>%
  ggplot(mapping = aes(x = value,
                       y = features,
                       color = last_used_observation)) +
  geom_point(position = position_dodge2(width = .4, reverse = TRUE), shape = 1, alpha = .5) +
  geom_point(data = ls_hyperparameters$df_all_hp_best1 %>% filter(model == "enet"),
             position = position_dodge2(width = .4, reverse = TRUE),
             mapping = aes(color = "Best")) +
  scale_color_manual(values = c(viridis::viridis(n = 17), "red")) +
  facet_grid(starting_date ~ hyperparameter, scales = "free_x", switch = "both") +
  theme_bw() +
  labs(x = "Hyperparameter value",
       y = "Update Date",
       color = "HP update")


ggpubr::ggarrange(plot_best_numeric_hp_reservoir,
                  plot_best_numeric_hp_enet,
                  plot_best_numeric_hp_xgboost,
                  nrow = 3,
                  ncol = 1,
                  common.legend = TRUE,
                  legend = "bottom")

```

# Time and carbon footprint

```{r}
df_emissions <- lapply(X = vec_path_experience, FUN = fct_compute_emissions) %>%
  bind_rows(.id = "rep")

vec_time_labeller <- c("CO2eq (kg)",
                       "Energy (kWh)",
                       "Time (h)")
names(vec_time_labeller) <- c("total_mean_emissions",
                              "total_mean_energy",
                              "total_mean_time")
```

```{r}
#| fig-cap: "Execution time, energy consumption and carbon footprint by algorithm starting at 2021-03-01.."
#| fig-height: 6
#| 
df_emissions %>%
  filter(starting_date == "2021-03-01") %>%
  select(rep, model, starting_date, features, train_test, starts_with("total")) %>%
  tidyr::pivot_longer(cols = starts_with("total")) %>%
  group_by(model, starting_date, features, train_test, name) %>%
  summarise(median = median(value),
            min = min(value),
            max = max(value),
            .groups = "drop") %>%
  ggplot(mapping = aes(x = features, y = median, ymin = min, ymax = max, color = model)) +
  geom_point(position = position_dodge(width = .5)) +
  geom_errorbar(position = position_dodge(width = .5), width = 0) +
  scale_color_manual(values = color_methods) +
  facet_wrap(name ~ train_test,
             scales = "free_y",
             labeller = labeller(name = vec_time_labeller),
             ncol = 2) +
  theme_bw() +
  labs(shape = "Train or test set",
       color = "Model",
       x = "Features")

```

```{r}
#| fig-cap: "Mean Absolute Error and Carbon footprint by algorithm starting at 2021-03-01."
#| fig-height: 4
#| 
df_performance_vs_CO2_tempCO2 <- df_emissions %>%
  group_by(rep, model, starting_date, features) %>%
  summarise(total_mean_emissions = sum(total_mean_emissions),
            .groups = "drop") %>%
  group_by(model, starting_date, features) %>%
  summarise(median_total_mean_emissions = median(total_mean_emissions),
            min_total_mean_emissions = min(total_mean_emissions),
            max_total_mean_emissions = max(total_mean_emissions),
            .groups = "drop")

df_performance_vs_CO2 <- df_perf_all_rep %>%
  filter(update == "Monthly update",
         starting_date == "2021-03-01") %>%
  group_by(model, starting_date, features) %>%
  summarise(median_MAE = median(MAE),
            min_MAE = min(MAE),
            max_MAE = max(MAE),
            .groups = "drop") %>%
  left_join(df_performance_vs_CO2_tempCO2,
            by = c("model", "starting_date", "features"))

df_performance_vs_CO2 %>%
  ggplot(mapping = aes(x = median_total_mean_emissions, y = median_MAE,
                       xmin = min_total_mean_emissions, xmax = max_total_mean_emissions,
                       ymin = min_MAE, ymax = max_MAE,
                       color = model, shape = features)) +
  geom_point(size = 3) +
  geom_errorbar(width = 0) +
  geom_errorbarh(height = 0) +
  scale_color_manual(values = color_methods) +
  scale_shape_manual(values = c(8, 18)) +
  theme_bw() +
  labs(x = "train + test CO2eq (kg)",
       y = "Mean Absolute Error",
       color = "Model",
       shape = "Features")
```

